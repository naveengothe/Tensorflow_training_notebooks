{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install 'transformers[torch]'"
      ],
      "metadata": {
        "id": "YQFicNAHZQzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.nn import functional as F\n",
        "tokenizer = AutoTokenizer.from_pretrained('deepset/sentence_bert')\n",
        "model = AutoModel.from_pretrained('deepset/sentence_bert')\n",
        "\n",
        "sentence = 'Who are you voting for in 2020?'\n",
        "\n",
        "labels = ['business', 'art & culture', 'politics']\n",
        "\n",
        "# run inputs through model and mean-pool over the sequence\n",
        "# dimension to get sequence-level representations\n",
        "inputs = tokenizer.batch_encode_plus([sentence] + labels,\n",
        "                                     return_tensors='pt',\n",
        "                                     pad_to_max_length=True)\n",
        "input_ids = inputs['input_ids']\n",
        "attention_mask = inputs['attention_mask']\n",
        "\n",
        "output = model(input_ids, attention_mask=attention_mask)[0]\n",
        "\n",
        "sentence_rep = output[:1].mean(dim=1)\n",
        "label_reps = output[1:].mean(dim=1)\n",
        "\n",
        "# now find the labels with the highest cosine similarities to\n",
        "# the sentence\n",
        "similarities = F.cosine_similarity(sentence_rep, label_reps)\n",
        "closest = similarities.argsort(descending=True)\n",
        "for ind in closest:\n",
        "    print(f'label: {labels[ind]} \\t similarity: {similarities[ind]}')\n"
      ],
      "metadata": {
        "id": "xs27GhEmb4rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " zero-shot-classification pipeline to infer with zero shot text classification models."
      ],
      "metadata": {
        "id": "ksM-ndKBbVDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(model=\"facebook/bart-large-mnli\")\n",
        "pipe(\"I have a problem with my iphone that needs to be resolved asap!\",\n",
        "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
        ")\n"
      ],
      "metadata": {
        "id": "JL4HDJGcZPnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model directly with a pipeline for masked language modeling:\n",
        "\n",
        "from transformers import pipeline\n",
        "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "unmasker(\"Hello I'm a [MASK] model.\")"
      ],
      "metadata": {
        "id": "A80rGQi9cYuI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}